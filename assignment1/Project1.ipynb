{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfUt7BmNzkIx"
   },
   "source": [
    "# Project 1: First steps in Machine Learning (20 Points)\n",
    "In this project, you will train and test your first machine learning models. Please follow the todos in this notebook. Note that for the description areas you are supposed to write a short text answering the questions.\n",
    "\n",
    "You should work in a group of 3 students. Please enter your names and your TA here:\n",
    "Students:\n",
    "TA:\n",
    "\n",
    "This assignment is due on **Friday, 29.11.2020 11:59am**. Please upload your solution to the Lernraum+.\n",
    "\n",
    "\n",
    "TODO: Ausführliche Antworten enforcen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCtZ5SsNSvT8"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<marquee style='width: 100%; color: white;'><font size=\"10\" color=\"magenta\"><b>Welcome to Introduction To Machine Learning!</b></font></marquee>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCypy1U8zkI0"
   },
   "source": [
    "## kNN - Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "197KcJbGzkI3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# load dataset 1\n",
    "data_set = np.load('/dataset_1.npz')\n",
    "X_train = data_set['X_train']\n",
    "X_test = data_set['X_test']\n",
    "y_train = data_set['y_train']\n",
    "y_test = data_set['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95E_mzY1zkJG"
   },
   "source": [
    "**todo:** describe the dataset briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pp0Fida7zkJA"
   },
   "outputs": [],
   "source": [
    "# todo: take a closer look at the dataset, e.g. number of samples, dimensionality, labels, etc.\n",
    "print(\"shape of the datasets:\",\n",
    "      f\"\\nX_train : {X_train.shape}\",\n",
    "      f\"\\nX_test  : {X_test.shape}\",\n",
    "      f\"\\ny_train : {y_train.shape}\",\n",
    "      f\"\\ny_test  : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNH4LvGS8sUd"
   },
   "outputs": [],
   "source": [
    "# Let's have a look how our data and its labels look like\n",
    "datasets = {\"train\": {\"X\": X_train, \"y\": y_train},\n",
    "            \"test\":  {\"X\": X_test,  \"y\": y_test}}\n",
    "\n",
    "for key, s in datasets.items():\n",
    "    print(f\"Samples from {key} set:\")\n",
    "    for i in range(10):\n",
    "        print(f\"Data sample #{i}: \", s[\"X\"][i], \" \\tLabel: \", s[\"y\"][i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRBN9xps8tYV"
   },
   "outputs": [],
   "source": [
    "# Let's check how many classes/labels we have in our data\n",
    "print(\"There are {} labels/classes in 'y_train' and they are stored as: {}\".format(len(set(y_train)), set(y_train)),\n",
    "      \"\\n# of elements stored as 0: \", len(y_train[y_train == 0]),\n",
    "      \"\\n# of elements stored as 1: \",len(y_train[y_train == 1]),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqyaX6_m_LtP"
   },
   "outputs": [],
   "source": [
    "# Let's check how many classes/labels we have in our data\n",
    "print(\"There are {} labels/classes in 'y_test' and they are stored as: {}\".format(len(set(y_test)), set(y_test)),\n",
    "      \"\\n# of elements stored as 0: \", len(y_test[y_test == 0]),\n",
    "      \"\\n# of elements stored as 1: \",len(y_test[y_test == 1]),\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-G-3Qj8zkJH"
   },
   "source": [
    "**todo:** describe the kNN classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yoR7mM5o81n-"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Create a Bernouilli Naive Bayes instance. You are highly encouraged to play with the values of the parameters. Refer to the following address for more info:\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Accuracy of kNN is: \", accuracy_score(y_test, y_test_pred))\n",
    "#print(multilabel_confusion_matrix(y_test, y_test_pred))\n",
    "print(\"\\n\",confusion_matrix(y_test, y_test_pred))\n",
    "# print clf report. More info: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "print(\"\\n\",classification_report(y_test, y_test_pred, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FY4-FS3LzkJI"
   },
   "outputs": [],
   "source": [
    "# todo: train and test the kNN classifier for different values of k on dataset 1. Plot the accuracy for different values of k\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = []\n",
    "for i in range(1, len(X_train)):\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jj9gs2h4Lbx"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=((20,7)))\n",
    "plt.plot(range(1,len(X_train)), scores)\n",
    "plt.title(\"Accuracy score on Test set for different values of $k$\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('$k$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFI3a5b745Jf"
   },
   "outputs": [],
   "source": [
    "scores_train = []\n",
    "for i in range(1, len(X_train)):\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    scores_train.append(accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "plt.figure(figsize=((20,7)))\n",
    "plt.plot(range(1,len(X_train)), scores_train)\n",
    "plt.title(\"Accuracy score on Train set for different values of $k$\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('$k$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoj8y_WWzkJQ"
   },
   "source": [
    "**todo:** let's analyze our findings:\n",
    "* For which values of k does the model perform best?\n",
    "* Would this value perform best on another dataset as well?\n",
    "* How can k be choosen?\n",
    "* What is the smallest and the greatest possible value for k? What would happen if we would choose these special values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxex3z5tzkJR"
   },
   "source": [
    "## Logistic Regression\n",
    "Let's try another model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhB-OKu6zkJS"
   },
   "outputs": [],
   "source": [
    "# todo: load dataset 2 and analyze the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucZ0dg1NA60N"
   },
   "outputs": [],
   "source": [
    "# load dataset 2\n",
    "data_set = np.load('/dataset_2.npz')\n",
    "X_train = data_set['X_train']\n",
    "X_test = data_set['X_test']\n",
    "y_train = data_set['y_train']\n",
    "y_test = data_set['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr-DXalVA60W"
   },
   "outputs": [],
   "source": [
    "# todo: take a closer look at the dataset, e.g. number of samples,\n",
    "# dimensionality, labels, etc.\n",
    "print(\"shape of the datasets:\",\n",
    "      f\"\\nX_train : {X_train.shape}\",\n",
    "      f\"\\nX_test  : {X_test.shape}\",\n",
    "      f\"\\ny_train : {y_train.shape}\",\n",
    "      f\"\\ny_test  : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4yBvcNAA60b"
   },
   "outputs": [],
   "source": [
    "# Let's have a look how our data and its labels look like\n",
    "datasets = {\"train\": {\"X\": X_train, \"y\": y_train},\n",
    "            \"test\":  {\"X\": X_test,  \"y\": y_test}}\n",
    "\n",
    "for key, s in datasets.items():\n",
    "    print(f\"Samples from {key} set:\")\n",
    "    for i in range(10):\n",
    "        print(f\"Data sample #{i}: \", s[\"X\"][i], \" \\tLabel: \", s[\"y\"][i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEUt2wCBA60n"
   },
   "outputs": [],
   "source": [
    "# Let's check how many classes/labels we have in our data\n",
    "print(\"There are {} labels/classes in 'y_train' and they are stored as: {}\".format(len(set(y_train)), set(y_train)),\n",
    "      \"\\n# of elements stored as -1: \", len(y_train[y_train == -1]),\n",
    "      \"\\n# of elements stored as 1: \",len(y_train[y_train == 1]),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqcdoQj4A60r"
   },
   "outputs": [],
   "source": [
    "# Let's check how many classes/labels we have in our data\n",
    "print(\"There are {} labels/classes in 'y_test' and they are stored as: {}\".format(len(set(y_test)), set(y_test)),\n",
    "      \"\\n# of elements stored as -1: \", len(y_test[y_test == -1]),\n",
    "      \"\\n# of elements stored as 1: \",len(y_test[y_test == 1]),\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dygg6SnkzkJX"
   },
   "source": [
    "**todo:** describe logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4G-Hd6pzkJY"
   },
   "outputs": [],
   "source": [
    "# todo: train and test logistic regression on dataset 2, plot the dataset and the decision boundary w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nBBLXJMBSqI"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a Logistic Regression instance. You are highly encouraged to play with\n",
    "# the values of the parameters. Refer to the following address for more info:\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "model = LogisticRegression(penalty='l1', C=0.5, solver='liblinear', multi_class='ovr')\n",
    "# We fit our trainig data to our model. This is where the 'learning' occurs!\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Let's test our model with our test data using the 'predict()' method\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Accuracy of kNN is: \", accuracy_score(y_test, y_test_pred))\n",
    "print(\"\\n\",confusion_matrix(y_test, y_test_pred))\n",
    "# print clf report. More info: \n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "print(\"\\n\",classification_report(y_test, y_test_pred, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oL_9WjMb7bpz"
   },
   "outputs": [],
   "source": [
    "# Generate a figure\n",
    "plt.figure(figsize=((15,7)))\n",
    "# Get the model parameters/coefficients\n",
    "w = model.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "# Create a linear space to draw the decision boundary. x values in 2-d (x,y) \n",
    "# coordinate system\n",
    "xx = np.linspace(-4, 4)\n",
    "# Calculate the y values for the generated x values in (x,y) coord. by using the\n",
    "# model coefficients and the bias/intercept\n",
    "yy = a * xx - (model.intercept_[0]) / w[1]\n",
    "# Plot the decision boundary\n",
    "plt.plot(xx, yy, 'b-', label=\"decision boundary\")\n",
    "\n",
    "# Iterate over the labels in 'y_train' and plot the data points for each class\n",
    "for i,j in enumerate(np.unique(y_train)):\n",
    "    plt.scatter(X_train[y_train==j, 0],    # x-coord. 1st column in 'X_train'\n",
    "                X_train[y_train==j, 1],    # y-coord. 2nd column in 'X_train'\n",
    "                color=ListedColormap(('r', 'g'))(i),  # specify the color of data points\n",
    "                label=f\"Class {j}\",        # specify the label of data points\n",
    "                )\n",
    "\n",
    "plt.xlabel(\"X_train[0]\")\n",
    "plt.ylabel(\"X_train[1]\")\n",
    "plt.title(\"Training set with the decision boundary\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b74qJN03zkJe"
   },
   "source": [
    "**todo:** w separates the classes. How does the negative log-likelihood (NLL) change for α*w as α goes to infty?\n",
    "\n",
    "**Hint:** Let the new NLL computed by an own function and report the NLL for different values.\n",
    "   \n",
    "What can you infer from your observations regarding the training of a model?\n",
    "\n",
    "**Hint:** You can analyze both cases, y=0 and y=1, and find a limit of the likelihood for one sample. Then, calculate the limit of the negative log-likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edHXCg-IzkJg"
   },
   "source": [
    "## Comparing kNN and Logistic Regression\n",
    "Finally, we want to compare the kNN and the logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOIj3_vUzkJh"
   },
   "outputs": [],
   "source": [
    "# todo: train both kNN and logistic regression on dataset 1 and 2. Plot the datasets.\n",
    "# You can plot the decision boundary of the classifiers using plot_2d_decisionboundary() in utils.py\n",
    "\n",
    "from utils import plot_2d_decisionboundary\n",
    "from utils import plot_classification_dataset\n",
    "\n",
    "\n",
    "def train(dataset):\n",
    "    \"\"\"\n",
    "    Train kNN & Log.Reg. on a given dataset and plot the dataset as well as the\n",
    "    model's decision boundary\n",
    "    \n",
    "    Params:\n",
    "        dataset: name of the datase\n",
    "    \n",
    "    Examples:\n",
    "        train('dataset_1')\n",
    "    \"\"\"\n",
    "    # load dataset\n",
    "    data_set = np.load(f'/{dataset}.npz')\n",
    "    X_train = data_set['X_train']\n",
    "    X_test = data_set['X_test']\n",
    "    y_train = data_set['y_train']\n",
    "    y_test = data_set['y_test']\n",
    "\n",
    "    # Construct models and do training\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    log_reg = LogisticRegression(penalty='l1', C=0.5, solver='liblinear', multi_class='ovr')\n",
    "    # Iterate over models & do training on each model\n",
    "    models = [knn, log_reg]\n",
    "    for model in models:\n",
    "        # Fit data, in other words start training\n",
    "        model.fit(X_train, y_train)\n",
    "        # Get the predictions on 'X_test'\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        print(f\"Accuracy of {model} is: \", accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "        # Plot dataset & decision boundary\n",
    "        print(f\"\\t{dataset} | training data: \")\n",
    "        plot_classification_dataset(X_train, y_train)\n",
    "        print(f\"\\t{dataset} | test data: \")\n",
    "        plot_2d_decisionboundary(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hk5PwGElGxIc"
   },
   "outputs": [],
   "source": [
    "train(\"dataset_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iP1yimpG2rB"
   },
   "outputs": [],
   "source": [
    "train(\"dataset_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANBVeSXjzkJn"
   },
   "source": [
    "**todo:** Describe your results and analyze them: is one model performing better than the other? Is there a difference in the datasets causing this behavior? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZZskl-5zkJo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HCypy1U8zkI0",
    "qxex3z5tzkJR",
    "edHXCg-IzkJg"
   ],
   "name": "Copy of Project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
